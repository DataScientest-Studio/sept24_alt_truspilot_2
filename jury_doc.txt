============================
DOCUMENT : Ã€ DIRE AU JURY
Projet Trustpilot - Pierre Poulouin
============================

ğŸ¬ 1. Phase de preprocessing (nettoyage et prÃ©paration)
------------------------------------------------------
â€œJe suis parti du fichier `trustpilot_dataset_final_cleaned.csv`, qui rassemble les avis des diffÃ©rentes marques quâ€™on a scrappÃ©es.
Ã€ cette Ã©tape, lâ€™objectif Ã©tait de nettoyer le texte pour obtenir une variable exploitable par un modÃ¨le de Machine Learning.

Jâ€™ai fusionnÃ© le `Title` et le `Content` quand les deux existaient, supprimÃ© les caractÃ¨res spÃ©ciaux, passÃ© les textes en minuscules et enlevÃ© les mots inutiles (stopwords).

Ensuite, jâ€™ai crÃ©Ã© une colonne `CleanText`, qui devient la base textuelle de tout le projet.

Ce choix est important, car il permet dâ€™avoir une structure homogÃ¨ne et rÃ©utilisable pour tous les modÃ¨les, que ce soit en multiclass ou en binaire.â€

------------------------------------------------------

ğŸ“Š 2. DÃ©coupage du dataset (split train/test)
------------------------------------------------------
â€œUne fois le dataset nettoyÃ©, jâ€™ai utilisÃ© le script `split_train_test.py` pour crÃ©er un split stratifiÃ© 80/20.

La stratification permet de prÃ©server la proportion de notes 1 Ã  5 entre le train et le test.
Câ€™est essentiel pour avoir une Ã©valuation honnÃªte du modÃ¨le.

Ce dÃ©coupage produit les fichiers `data/processed/train.csv` et `data/processed/test.csv`, qui servent de base commune Ã  toutes les expÃ©riences.

Jâ€™ai choisi de garder ce split unique comme rÃ©fÃ©rence pour Ã©viter de biaiser les comparaisons entre les diffÃ©rents modÃ¨les.â€

------------------------------------------------------

ğŸ¤– 3. ModÃ©lisation multiclass (1 Ã  5 Ã©toiles)
------------------------------------------------------
â€œDans un premier temps, jâ€™ai entraÃ®nÃ© un modÃ¨le de classification multiclasses sur 5 classes (notes 1 Ã  5).

Lâ€™objectif Ã©tait de prÃ©dire la note exacte dâ€™un avis client.

Le modÃ¨le utilisÃ© Ã©tait une rÃ©gression logistique avec reprÃ©sentation TF-IDF, un choix simple, robuste et interprÃ©table.

Les rÃ©sultats ont montrÃ© que le modÃ¨le reconnaissait bien les notes extrÃªmes (1 et 5), mais avait plus de mal Ã  distinguer les notes proches, notamment 3, 4 et 5.

En regardant la matrice de confusion normalisÃ©e, on remarque que la note 3 est la plus difficile Ã  prÃ©dire, souvent confondue avec 4 ou 5.

Câ€™est un comportement classique : le langage des avis moyens est souvent trÃ¨s proche de celui des avis positifs.â€

------------------------------------------------------

ğŸ”„ 4. Justification du passage en binaire
------------------------------------------------------
â€œSuite Ã  cette analyse, jâ€™ai fait le choix de transformer le problÃ¨me en classification binaire, ce qui est une pratique courante en NLP quand les classes sont trop proches.

ConcrÃ¨tement, jâ€™ai regroupÃ© les notes 1 et 2 dans la classe â€˜mauvaisâ€™, et les notes 3, 4 et 5 dans la classe â€˜bonâ€™.

Lâ€™objectif est de rÃ©pondre Ã  une question plus simple et plus mÃ©tier :
â€˜Est-ce que lâ€™avis est globalement positif ou nÃ©gatif ?â€™

Jâ€™ai utilisÃ© le script `make_reports_from_predictions.py` pour dÃ©montrer que cette transformation Ã©tait pertinente.

Les courbes ROC et les matrices binaires ont confirmÃ© que le modÃ¨le se comportait beaucoup mieux : les classes sont bien sÃ©parÃ©es et la performance augmente fortement.

Cette Ã©tape sert donc de preuve par les chiffres avant de rÃ©entraÃ®ner un vrai modÃ¨le binaire.â€

------------------------------------------------------

âš™ï¸ 5. RÃ©entraÃ®nement du modÃ¨le binaire (`train_binary.py`)
------------------------------------------------------
â€œUne fois la pertinence prouvÃ©e, jâ€™ai rÃ©entraÃ®nÃ© un modÃ¨le spÃ©cifiquement binaire avec le script `train_binary.py`.

Ce modÃ¨le utilise le mÃªme pipeline TF-IDF + Logistic Regression, mais cette fois, il apprend directement sur la cible binaire (0 ou 1).

Jâ€™ai aussi intÃ©grÃ© un RandomOverSampler uniquement sur le jeu dâ€™entraÃ®nement pour corriger le lÃ©ger dÃ©sÃ©quilibre entre les classes.

Le modÃ¨le est ensuite Ã©valuÃ© sur le jeu de test, jamais vu pendant lâ€™entraÃ®nement.â€

------------------------------------------------------

ğŸ“ˆ 6. RÃ©sultats et interprÃ©tation
------------------------------------------------------
â€œLe modÃ¨le binaire atteint un F1-score de 0.96, avec un AUC de 0.98 et une prÃ©cision globale de 95 %.

Les matrices de confusion montrent trÃ¨s peu dâ€™erreurs, et les deux seuils (0.5 et optimal Ã  0.51) donnent presque les mÃªmes rÃ©sultats, ce qui montre que le modÃ¨le est stable et bien calibrÃ©.

La courbe Precisionâ€“Recall est presque parfaite (AP = 0.99), preuve que le modÃ¨le garde une grande fiabilitÃ© mÃªme sur les classes minoritaires.

Ce modÃ¨le est donc Ã  la fois performant, explicable et pertinent pour un usage mÃ©tier.â€

------------------------------------------------------

ğŸ§  7. StratÃ©gie dâ€™amÃ©lioration (features et bonnes pratiques)
------------------------------------------------------
â€œEn tant que Data Scientist, jâ€™ai choisi de garder ce modÃ¨le comme baseline officielle, car il est dÃ©jÃ  excellent et simple Ã  maintenir.

Ajouter des features maintenant risquerait de complexifier inutilement le pipeline pour un gain marginal.

En revanche, jâ€™ai prÃ©vu un second script `train_binary_features.py` pour tester Ã  part lâ€™ajout de quelques features interprÃ©tables : longueur du texte, nombre dâ€™exclamations, ratio de majuscules, subjectivitÃ©, etc.

Si ces features apportent un vrai gain, je les intÃ©grerai dans une version 2.
Sinon, je privilÃ©gierai la simplicitÃ© et la stabilitÃ© du modÃ¨le actuel.â€

------------------------------------------------------

ğŸ§¾ 8. Conclusion gÃ©nÃ©rale 
------------------------------------------------------
Le projet a suivi une approche progressive et rigoureuse :
- Nettoyage et normalisation du texte,
- Construction dâ€™un pipeline TF-IDF + Logistic Regression,
- Ã‰valuation multiclass puis binaire,
- Et validation dâ€™un modÃ¨le robuste, simple et performant.

Ce travail prouve quâ€™on peut atteindre dâ€™excellents rÃ©sultats avec un modÃ¨le classique bien prÃ©parÃ©, sans recourir Ã  des architectures complexes.

La prochaine Ã©tape, si le temps le permet, sera dâ€™ajouter des features explicatives pour renforcer encore la performance, ou de tester un modÃ¨le plus moderne type SVM ou BERT.

Mais la version actuelle rÃ©pond dÃ©jÃ  trÃ¨s bien Ã  la question initiale du projet :
â€˜Un client est-il globalement satisfait ou non ?â€™
